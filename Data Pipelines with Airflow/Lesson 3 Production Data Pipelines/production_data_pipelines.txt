-------------------- Production Data Pipelines -------------------- 
Objective 
â€¢ Learn how to build maintainable and reusable pipelines in Airlow




-------------------- Extending Airflow with Plugins -------------------- 
Airflow was built with the intention of allowing its users to extend and customize its funtinality through plugins. The most common types of user-created plugins for Airflow are Operators and Hooks. These plugins make Dags reusable and simpler to maintain. 

To create custom opertator, follow the steps: 
1. Identify Operators that perfom simialr functions and can be consolidated.
2. Define a new Operator in the plugins folder
3. Replace the original Operators with your new custom one, re-parameterize, and instantiate them. 




-------------------- Extending Airflow Hooks & Contrib --------------------
Airflow Contrib
Airflow has a rich and vibrant open source community. This community is contantly adding new functionality and extending the capablities of Ariflow. As as Airflow user, you should always check Airflow Contrib before building your own airflow plugins, to see if what you need already exists.

Operators and hooks for common data tools like Apache Spark and Cassandra, as well as vendor specific integrations for Amazon Web Services, Azure and Google Cloud Platform can be found in Airlfow contrib. If the functionality exists and its not quite what you want, thats a greats opportunity to add that functionality through an open source contribution. 
Check it out:
https://github.com/apache/airflow/tree/master/airflow/contrib






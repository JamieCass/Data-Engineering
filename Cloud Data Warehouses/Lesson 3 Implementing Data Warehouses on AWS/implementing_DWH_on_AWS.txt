-------------------- IMPLEMENTING A DWH ON AWS --------------------
-- Choices for implementing a Data warehouse:
1. Cloud:
   	• Lower barrier to entry
   	• May add as you need - its ok to change your opinion
   	• Scalability & elasticity out of the box


2. On-Premise:
   Thik about:
   	• Heterogeneity, scalability, elasticity of the tools, technologies and processes.
   	• Need for diversse IT staff skills & multiple locatioons
   	• Cost of ownership


----- DWH Dimensional model storage on AWS -----
-- Cloud-Managed:
	• Amazon RDS (Relational Data Storage)
	• Amazon DynamoDB
	• Amazon S3
	Re-use of expertise; Less IT staff for security, upgrades, etc.. Less OpEx
	Deal with complexity with techniques like: 'Infrastructure as code'

-- Self-Managed:
	• EC2 + PostgreSQL
	• EC2 + Cassandra
	• EC2 + Unix FS
	Always 'catch-all' option if needed


														- AWS RDS
												SQL --->- Redshift
		     -> Cloud 		-> Cloud-managed -> NoSQL	  SQL based
		    |									Files     Columnar
DWH Storage |											  Massively parralel
			|
			 -> On-Premise 	-> Self-Managed  -> EC2 + ?




-------------------- Amazon Redshift Technology --------------------
• Column-oriented storage
• Best suited for storing OLAP workloads, summing over a long history
• Internally, its a modified PostgreSQL 

----- Most relational DB -----
- Most relational databases execute multiple queries in parallel if they have access to many cores/servers
- However, every query is always executed on a single CPU of a single machine
- Acceptable for OLTP mostly updates and few rows retrieval

----- MPP -----
- Massively Parallel Processing (MPP) databses parallelizee the execution of one query on multiple CPU's/machines
- How? A table is pertitioned and pertitions are processed in parallel
- Redshift is a cloud managed, column-oriented, MPP database
- Other examples include Teradata, Aster, Oracle Exadata & Azure SQL




-------------------- Amazon Redshift Architecture --------------------
• Client Applications
		|
		v
• Leader Node
	- Coordinates compute nodes
	- HAndles external communication
	- Optimizes query execution
		|
		v
• Compute node 1   -   Compute node n 
	- Each with its own CPU, memory and disk
	- Scale up: get more powerful nodes
	- Scale out: get more nodes
		|
		v
• Node slices
	- Each compute node is logically divided into a number of slices
	- A cluster with n slices can process n partitions of tables simultaneously
		|
		v
• Datawaehouse cluster




-------------------- SQL to SQL ETL --------------------
How would you insert from one table into another table on a different server?

General Solution (see pictures in folder)
----------------
DB Server 1 (e.g. mysql)
(An ETL server can talk to teh source server and run a SELECT query on the source DB server)
			|
		  SELECT
		 	|
			v
		ETL Server
(Stotres the results in CSV files.. Needs large storage)
			| 
		INSERT/COPY
			|
			v
DB Server 2 (e.g. postresql)
(INSERT/COPY the resukts in the destination DB server)



-------------------- SQL to SQL ETL (AWS Case) --------------------
For the AWS example, we store all the data in S3 buckets and just use the EC2 machine to act as a client to RDS and Redshift to issue COPY commands, (we dont need storage on the EC3 machine).

AWS Solution (see pictures in folder)
------------
ETL server(EC2) To talk to AWS RDS instance
	|
	v
AWS RDS
(Copy CSV to S3 Bucket)
	|
	v
ETL server(EC2) to talk to Redshift instance
	|
	v
Redshift
(Copy CSV from S3 Bucket)

S3 offers a very reliable, scalable and worry-free storage solution, but it doesnt offer processing power.






